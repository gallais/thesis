\chapter{Introduction}
\label{introduction}

In modern typed programming languages, programmers writing embedded Domain
Specific Languages (DSLs) (\cite{hudak1996building}) and researchers
formalising them can now get help from the host language's type system
to make illegal states unrepresentable. Their language's deep embeddings
as inductive types can enforce strong invariants, their programs can be
proven to be invariant-respecting, and they can even prove theorems about
these programs.

\section{A Motivating Example}

The representation of variables and binders gives us a prototypical
example of the benefits an astute type-based design can bring. Let
us quickly survey different representations of the untyped λ-calculus,
informally given by the following grammar:

\[
t, u, \dots ∷= x \mid λx.\,t \mid t \, u
\]

\subsection{Naïve Representation}

Closely following the informal specification leads us to a naïve
solution: introduce an inductive type to represent terms and use
strings to represent variables. A variable is bound by the closest
enclosing binder that uses the same string. For example in the
expression (λx.λx.x) the variable x in the body of the expression is
bound by the innermost λ-abstraction.

This means that some terms may be essentially the same despite using
different names e.g. the above expression is equivalent to (λy.λx.x).
%
This notion of equivalence up to renaming is called
α-equivalence~(\cite{DBLP:books/daglib/0067558}) and it is clearly
going to be a bit tricky to implement: given two terms we may need
to rename all of their bound variables to decide whether they are
α-equivalent.

\subsection{Nameless Representation}

The problem of having to rename variables to compare terms for
equality can be solved by adopting a nameless representation
based on a positional system.
%
We can for instance represent variables as de Bruijn indices
(\citeyear{de1972lambda}): variables are modelled as natural numbers,
counting the number of enclosing binders one needs to go through before
reaching the binder the variable points to. That is to say that we
represent both (λx.λx.x) \emph{and} (λy.λx.x) by the term (λ.λ.0).

This solution is not perfect either: if a natural number is larger
than the number of enclosing binders, the variable is free. When
substituting a term containing free variables into a term containing
binders, we need to remember to increment the natural numbers
corresponding to free variables (and only those) every time we push
the substitution under a binder. This is quite error prone.

\subsection{Well Scoped Representation}

As we have just seen, directly manipulating a string-based representation
or even one using raw de Bruijn indices is error-prone. As a consequence,
managing variable binding by making the scope part of the typing discipline
is a popular use case
(\cite{BELLEGARDE1994287,bird_paterson_1999,altenkirch1999monadic}).

We will study this representation in more details in
Section~\ref{sec:scopedtypedterms} but the key idea is that the number
of free variables is made to be part of the type of terms. This means that
if the programmer has forgotten to appropriately update a term before pushing
it under a binder, they will get a static type error.

The illegal state has been made irrepresentable thus rooting out a source
of errors.

\section{Scope of This Thesis}

This thesis focuses on the representations providing users with strong
built-in guarantees. It covers the data representations, the programs
acting on this data and the proofs that these programs are well-behaved.

\paragraph{Data}
Using Generalised Algebraic Data Types (GADTs) or the more general indexed
families of type theory (\cite{dybjer1994inductive}) for representing their
syntax, programmers can \emph{statically} enforce some of the invariants
in their languages.

Solutions range from enforcing well scopedness to ensuring full type and scope
correctness. In short, we use types to ensure that ``illegal states are unrepresentable'',
where illegal states are ill scoped or ill typed terms.

\paragraph{Programs}
The definition of \scopeandtypesafe{} representations is naturally only a start:
once the programmer has access to a good representation of the language they are
interested in, they will then want to (re)implement standard traversals
manipulating terms. Renaming and substitution are the two most typical examples
of such traversals. Other common examples include an evaluator, a printer for
debugging purposes and eventually various compilation passes such as a continuation
passing style transformation or some form of inlining. Now that well-typedness
and well-scopedness are enforced statically, all of these traversals have to be
implemented in a \scopeandtypesafe{} manner.

\paragraph{Proofs} This last problem is only faced by those that want really high assurance or whose
work is to study a language's meta-theory: they need to prove theorems about these
traversals. The most common statements are simulation lemmas stating that two
semantics transport related inputs to related outputs, or fusion lemmas demonstrating
that the sequential execution of two semantics is equivalent to a single traversal
by a third one. These proofs often involve a wealth of auxiliary lemmas which are
known to be true for all syntaxes but have to be re-proven for every new language
e.g. identity and extensionality lemmas for renaming and substitution.

Despite the large body of knowledge in how to use types to define well formed
syntax (see the related work in \cref{chapter:program-conclusion}), it is still
necessary for the working DSL designer or formaliser to redefine essential
functions like renaming and substitution for each new syntax, and then to
reprove essential lemmas about those functions.

\section{Our Contributions}

In this thesis we address all three challenges by applying the methodology of
datatype-genericity to programming and proving with syntaxes with binding.
We ultimately give a binding-aware syntax for well typed and scoped DSLs; we
spell out a set of sufficient constraints entailing the existence of a fold-like
type-and-scope preserving traversal; and we provide proof frameworks
to either demonstrate that two traversals are in simulation or that they can be
fused together into a third one.

The first and second parts of this work focus on the simply-typed lambda calculus.
We identify a large catalogue of traversals which can be refactored into a common
scope aware fold-like function. Once this shared structure has been made
visible, we can design proof frameworks allowing us to show that some traversals
are related.

The third part builds on the observation that the shape of the constraints we
see both in the definition of the generic traversal and the proof frameworks
are in direct correspondence with the language's constructors. This pushes us
to define a description language for syntaxes with binding and to \emph{compute}
the constraints from such a description. We can then write generic programs for
\emph{all} syntaxes with binding and state and prove generic theorems characterising
these programs.

\section{Source Material}

The core of this thesis is based on the content of two fully-formalised
published papers. They
correspond roughly to part one and two on the one hand
(``Type-and-scope Safe Programs and Their Proofs'' \cite{allais2017type, repo2017})
and part three on the other
(``A Type and Scope Safe Universe of Syntaxes with Binding: Their Semantics and Proofs''
\cite{generic-syntax, repo2018}).

The study of variations on normalisation by evaluation in \cref{sec:variationsnormalisation}
originated from the work on a third paper ``New equations for neutral terms''
(\cite{new-equations}) which, combined with McBride's Kit for renaming and substitution
(\citeyear{mcbride2005type}), led to the identification of a shared structure between renaming,
substitution and the model construction in normalisation by evaluation.

The first consequent application of this work is our solution to the
POPLMark Reloaded challenge
(\cite{poplmarkreloaded, poplmark2}) for which we formalised a proof of
strong normalisation for the simply-typed lambda-calculus (and its extension
with sum types, and primitive recursion for the natural numbers).


\section{Plan}

The work in this thesis brings together many strands of research so we provide
introductory chapters for the less common topics.

\subsection{Introductory Materials}

We use categorical terms whenever it is convenient to concisely describe some
of the key properties of our constructions. So we provide the reader with an
\textbf{introduction to category theory in Section~\ref{introduction-category}}.
A reader familiar with Pierce's `Basic category theory for computer scientists'
may skip this section except perhaps for the definition of relative monads
in Section~\ref{sec:relativemonad}.

% The internal language of this thesis is very much type theory. So we provide a
% short introduction in Section~\cref{}.

All of the content of this thesis has been fully formalised in Agda
(the code snippets have all been checked and typeset by Agda itself)
so we provide an \textbf{introduction to Agda and the conventions we
adopted in Section~\ref{introduction-agda}}.

Our work on generic programming with syntaxes with binding is heavily influenced
by prior results on generic programming for (indexed) inductive types. We offer
a \textbf{primer on data-generic programming in Section~\ref{section:data}}.

The \textbf{conventions and techniques}, and \textbf{Agda features} present
in these introductory materials are collected in the appendices
(Appendices \ref{sec:conventions} and \ref{sec:features} respectively).

\subsection{Contributions}

\paragraph{Part I} is dedicated to the study of a \scopeandtypesafe{}
representation of the simply typed lambda calculus with one sum type
(the booleans) and one product type (the unit type).
%
Starting from the inductive family used to represent terms in the language,
we study various invariant-respecting traversals and notice that they all
share the same structure. This leads us to see how they can all be unified
as instances of a single generic traversal.

\paragraph{Part II} identifies the constraints under which one can relate
different instances of the generic traversal. This yields simulation and
fusion lemmas for the generic traversal that can be immediately deployed
to obtain classic meta-theoretical results as direct corollaries.

\paragraph{Part III} builds on parts I and II and data-generic programming
to introduce syntax-generic programming and proving. It provides the user
with a whole universe of syntaxes with binding, their invariant-respecting
traversals, and proofs about these traversals.
