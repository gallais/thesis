s
\section{Introduction}

In modern typed programming languages, programmers writing embedded
DSLs~\cite{hudak1996building} and researchers formalising them can now
use the host language's type system to help them. Using Generalised
Algebraic Data Types (GADTs) or the more general indexed families of
Type Theory~\cite{dybjer1994inductive} for representing their syntax,
programmers can \emph{statically} enforce some of the invariants in
their languages. Managing variable scope is a popular use
case~\cite{altenkirch1999monadic} as directly manipulating raw de
Bruijn indices is error-prone.  Solutions range from enforcing well
scopedness to ensuring full type and scope correctness. In short, we
use types to ensure that ``illegal states are unrepresentable'', where
illegal states are ill scoped or ill typed terms.

Despite the large body of knowledge in how to use types to define well
formed syntax (see the Related Work in Section
\ref{section:related-work}), it is still necessary for the working DSL
designer or formaliser to redefine essential functions like renaming
and substitution for each new syntax, and then to reprove essential
lemmas about those functions. To reduce the burden of such repeated
work and boilerplate, we apply the methodology of datatype-genericity to
programming and proving with syntaxes with binding.

%%%%%% MOTIVATION


Using the universe of syntaxes with binding we present in this paper,
we are able to solve this repetition problem \emph{once and for all}.

%  For
% \emph{every} syntax in our universe, we are able to generically define
% renaming and substitution \ref{section:renandsub}, generically define
% the let-binding removal transformation \ref{section:letbinding}, and
% generically prove the required renaming, substitution and
% transformation fusion lemmas (\ref{section:fusion}.

\paragraph{Content and Contributions.}
We start with primers on scoped and sorted terms
(Section~\ref{section:primer-term}), scope and sort safe programs
acting on them (Section~\ref{section:primer-program}), and
programmable descriptions of data types (Section~\ref{section:data}).
These introductory sections help us build an understanding of the
problem at hand as well as a toolkit that leads us to the novel
content of this paper: a universe of scope safe syntaxes with binding
(Section~\ref{section:universe}) together with a notion of scope safe
semantics for these syntaxes (Section~\ref{section:semantics}).  This
gives us the opportunity to write generic implementations of renaming
and substitution (Section~\ref{section:renandsub}), a generic
let-binding removal transformation (generalising the problem stated
above) (Section~\ref{section:letbinding}), and normalisation by
evaluation (Section~\ref{section:nbyeval}). Further, we show how to
construct generic proofs by formally describing what it means for a
semantics to be able to simulate another one
(Section~\ref{section:simulation}), or for two semantics to be fusable
(Section~\ref{section:fusion}). This allows us to prove the lemmas
required above for renaming and substitution generically, for
\emph{every} syntax in our universe.

\medskip

Our implementation language is
Agda~\cite{norell2009dependently}. However, our techniques are
language independent: any dependently typed language at least as
powerful as Martin-L\"of Type Theory~\cite{martin1982constructive}
equipped with inductive families~\cite{dybjer1994inductive} such as
Coq~\cite{Coq:manual}, Lean~\cite{DBLP:conf/cade/MouraKADR15} or
Idris~\cite{brady2013idris} ought to do.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% SCOPE SAFE TERMS


\section{A Primer on Scope And Sort Safe Terms}\label{section:primer-term}

Scope safe terms follow the discipline that every variable is
either bound by some binder or is explicitly accounted for in a
context. Bellegarde and Hook~\citeyear{BELLEGARDE1994287}, Bird and Patterson~\citeyear{bird_paterson_1999},
and Altenkirch and Reus~\citeyear{altenkirch1999monadic} introduced the
classic presentation of scope safety using inductive
\emph{families}~\cite{dybjer1994inductive} instead of inductive types to
represent abstract syntax. Indeed, using a family indexed by a $\Set{}$,
we can track scoping information at the type level. The empty $\Set$ represents the empty scope. The functor
$1 + (\_)$ extends the running scope with an extra variable.

An inductive type is the fixpoint of an endofunctor on $\Set{}$.
Similarly, an inductive family is the fixpoint of an endofunctor on
$\Set \to \Set$. Using inductive families to enforce scope safety, we
get the following definition of the untyped $\lambda$-calculus: $T(F)
= \lambda X \!\in\! \Set{}.\; X + (F(X) \times F(X)) + F(1 + X)$.
This endofunctor offers a choice of three constructors.  The first one
corresponds to the variable case; it packages an inhabitant of $X$,
the index $\Set{}$. The second corresponds to an application node;
both the function and its argument live in the same scope as the
overall expression. The third corresponds to a $\lambda$-abstraction;
it extends the current scope with a fresh variable.  The language is
obtained as the fixpoint of $T$:
\[
   \mathit{Lam} = \mu F \in \Set{}^{\Set{}}.
   \lambda X \!\in\! \Set{}.\; X + (F(X) \times F(X)) + F(1 + X)
\]
Since `Lam' is a endofunction on Set, it makes
sense to ask whether it is also a functor and a monad. Indeed it is,
as Altenkirch and Reus have shown. The functorial action corresponds
to renaming, the monadic `return' corresponds to the use of variables,
and the monadic `join' corresponds to substitution. The functor and
monad laws correspond to well known properties from the equational
theories of renaming and substitution. We will revisit these properties
below in Section~\ref{section:fusion}.

\paragraph{A Mechanized Typed Variant of Altenkirch and Reus' Calculus.}\label{section:mech-reus}

There is no reason to restrict this technique to fixpoints of endofunctors
on $\Set{}^{\Set{}}$. The more general
case of fixpoints of (strictly positive) endofunctors on $\Set{}^J$ can be
endowed with similar operations by using Altenkirch, Chapman and
Uustalu's relative monads~\citeyear{Altenkirch2010, JFR4389}.

We pick as our $J$ the category whose objects are inhabitants of
\AD{List} \AB{I} (\AB{I} is a parameter of the construction) and whose morphisms are
thinnings (see Section~\ref{def:thinning}).  This \AD{List} \AB{I} is
intended to represent the list of the sort (/ kind / types depending
on the application) of the de Bruijn variables in scope. We can
recover an untyped approach by picking $I$ to be the unit type.  Given
this typed setting, our functors take an extra $I$ argument
corresponding to the type of the expression being built. This is
summed up by the large type \AB{I}
\AF{─Scoped}:% = $I$ $\to$ \AD{List} $I$ $\to$ \AF{Set}.

\begin{center}
\ExecuteMetaData[var.tex]{scoped}
%\caption{Type of Well \AB{I}-Kinded and Well Scoped Families}
\end{center}



%\begin{center}
\begin{minipage}[t]{0.35\textwidth}
\ExecuteMetaData[var.tex]{var}
\end{minipage}\hfill
\begin{minipage}[t]{0.55\textwidth}
\ExecuteMetaData[motivation.tex]{tm}
\end{minipage}
%\caption{Scope Aware Variables and Simply Typed $\lambda$-Terms\label{scoped-untyped}}
%\end{center}

The inductive family \AD{Var} represents well scoped and well kinded
de Bruijn~\citeyear{de1972lambda}
indices. Its \AIC{z} (for zero) constructor refers to
the nearest binder in a non-empty scope. The \AIC{s} (for successor) constructor lifts a
a variable in a given scope to the extended scope where
an extra variable has been bound. Both of the constructors' types have been written using the combinators defined above.
They respectively normalise to:
\begin{center}
  \AIC{z} : {\AS{∀} \AB{i} \AB{xs} \AS{→} \AD{Var} \AB{i} (\AB{i} \AIC{:\!:} \AB{xs})}
  \qquad
  \AIC{s} : {\AS{∀} \AB{i} \AB{j} \AB{xs} → \AD{Var} \AB{i} \AB{xs} \AS{→} \AD{Var} \AB{i} (\AB{j} \AIC{:\!:} \AB{xs})}
\end{center}

The \AD{Type} \AF{─Scoped} family \AD{Lam} is Altenkirch
and Reus' simply typed $\lambda$-calculus representation. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% SCOPE SAFE PROGRAMS


\section{A Primer on Type and Scope Safe Programs}\label{section:primer-program}

The scope-and-type safe representation described in the previous section is
naturally only a start: once the programmer has access to a good
representation of the language they are interested in, they will naturally
want to (re)implement standard traversals manipulating terms.
Renaming and substitution are the two most typical examples
of such traversals. Now that well-typedness and well-scopedness are enforced
statically, all of these traversals have to be implemented
in a type and scope safe manner.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% GENERIC PROOFS



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% FUSION


\begin{figure}[h]
 \ExecuteMetaData[Generic/Fusion.tex]{fusbody}
\caption{Fundamental Lemma of \AR{Fus}ion}
\end{figure}

\begin{figure}[h]
 \ExecuteMetaData[Generic/Fusion.tex]{subren}
\caption{A Corollary: Substitution-Renaming Fusion}
\end{figure}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% RELATED WORK

\section{Related Work}\label{section:related-work}

\subsection{Variable Binding} The representation of variable binding
in formal systems has been a hot topic for decades. Part of the purpose
of the first POPLMark challenge~\citeyear{poplmark} was to explore and
compare various methods.

Having based our work on a de Bruijn encoding of variables, and thus a
canonical treatment of \(\alpha\)-equivalence classes, our work has no
direct comparison with permutation-based treatments such as those of
Pitts' and Gabbay's nominal syntax~\cite{gabbay:newaas-jv}.

Our generic universe of syntax is based on
scope-and-typed de Bruijn indices~\cite{de1972lambda} but it is not
a necessity. It is for instance possible to give an interpretation
of \AD{Desc}riptions corresponding to Chlipala's Parametric Higher-Order
Abstract Syntax~\citeyear{chlipala2008parametric} and we would be interested
to see what the appropriate notion of Semantics is for this representation.

\subsection{Alternative Binding Structures} The binding structure we
present here is based on a flat, lexical scoping strategy. There are
other strategies and it would be interesting to see whether
our approach could be reused in these cases.

Bach Poulsen, Rouvoet, Tolmach, Krebbers and Visser~\citeyear{BachPoulsen}
introduce notions of scope graphs and frames to scale the techniques typical
of well scoped and typed deep embeddings to imperative languages. They can
already handle a large subset of Middleweight Java.

We have demonstrated how to write generic programs over the potentially
cyclic structures of Ghani, Hamana, Uustalu and Vene~\citeyear{ghani2006representing}.
Further work by Hamana~\citeyear{Hamana2009} yielded a different presentation
of cyclic structures which preserves sharing: pointers can not only refer
to nodes above them but also across from them in the cyclic tree. Capturing
this class of inductive types as a set of syntaxes with binding and writing
generic programs over them is still an open problem.

\subsection{Semantics of Syntaxes with Binding} An early foundational study
of a general \emph{semantic} framework for signatures with binding, algebras
for such signatures, and initiality of the term algebra, giving rise to a
categorical `program' for substitution and proofs of its properties, was given
by Fiore, Plotkin and Turi~\cite{FiorePlotkinTuri99}, working in the category of presheaves
over renamings, (a skeleton of) the category of finite sets. The presheaf
condition corresponds to our notion of being \AF{Thinnable}. Exhibiting
algebras based on both de Bruijn \emph{level} and \emph{index} encodings,
their approach isolates the usual (abstract) arithmetic required of such encodings.

By contrast, working in an \emph{implemented} type theory, where the encoding
can be understood as its own foundation, without appeal to an external mathematical
semantics, we are able to go further in developing machine-checked such
implementations and proofs, themselves generic with respect to an abstract syntax
\AD{Desc} of syntaxes-with-binding. Moreover, the usual source of implementation
anxiety, namely concrete arithmetic on de Bruijn indices, has been successfully
encapsulated via the \AF{□} coalgebra structure. It is perhaps noteworthy that
our type-theoretic constructions, by contrast with their categorical ones,
appear to make fewer commitments as to functoriality, thinnability, etc. in our
specification of semantics, with such properties typically being \emph{provable}
as a further instance of our framework.

\subsection{Meta-Theory Automation via Tactics and Code Generation} The
tediousness of repeatedly
proving similar statements has unsurprisingly led to various attempts at
automating the pain away via either code generation or the definition of
tactics. These solutions can be seen as untrusted oracles driving the
interactive theorem prover.

Polonowski's DBGen~\citeyear{polonowski:db} takes as input a raw syntax with
comments annotating binding sites. It generates a module defining lifting,
substitution as well as a raw syntax using names and a validation function
transforming named terms into de Bruijn ones; we refrain from calling it a
scopechecker as terms are not statically proven to be well scoped.

Kaiser, Schäfer, and Stark~\citeyear{Kaiser-wsdebr} build on our previous paper
to draft possible theoretical foundations for Autosubst, a so-far untrusted
set of tactics. The paper is based on a specific syntax: well-scoped call-by-value
System F. In contrast, our effort has been here to carve out
a precise universe of syntaxes with binding and give a systematic account
of their semantics and proofs.

Keuchel, Weirich, and Schrijvers' Needle~\citeyear{needleandknot} is a code
generator written in Haskell producing syntax-specific Coq modules
implementing common traversals and lemmas about them.

\subsection{Universes of Syntaxes with Binding} Keeping in mind Altenkirch
and McBride's observation that generic programming is everyday programming
in dependently-typed languages~\citeyear{genericprogramming-dtp}, we can naturally
expect generic, provably sound, treatments of these notions in tools such as
Agda or Coq.

Keuchel, Weirich, and Schrijvers' Knot~\citeyear{needleandknot} implements
as a set of generic programs the traversals and lemmas generated in specialised
forms by their Needle program. They see Needle as a pragmatic choice: working
directly with the free monadic terms over finitary containers would be too cumbersome. In
our experience solving the POPLMark Reloaded challenge, Agda's pattern
synonyms~\cite{Pickering:patsyn} make working with an encoded definition almost
seamless.

The GMeta generic framework~\citeyear{gmeta} provides a universe of syntaxes
and offers various binding conventions (locally nameless~\cite{Chargueraud2012}
or de Bruijn indices). It also generically implements common traversals (e.g. computing
the sets of free variables,
% measuring the size of a term,
shifting
de Bruijn indices or substituting terms for parameters) as well as common
predicates (e.g. being a closed term) and provides generic lemmas proving that
they are well behaved. It does not offer a generic framework
for defining new well scoped-and-typed semantics and proving their properties.

Érdi~\citeyear{gergodraft} defines a universe inspired by a first draft of this
paper and gives three different interpretations (raw, scoped and typed syntax)
related via erasure. He provides scope-and-type
preserving renaming and substitution as well as various generic proofs that
they are well behaved but offers neither a generic notion of semantics, nor
generic proof frameworks.

Copello~\citeyear{copello2017} works with \emph{named} binders and
defines nominal techniques (e.g. name swapping) and ultimately $\alpha$-equivalence
over a universe of regular trees with binders inspired by Morris'~\citeyear{morris-regulartt}.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% CONCLUSION

\section{Conclusion and Future Work}

Recalling Allais, Chapman, McBride and McKinna's earlier work~\citeyear{allais2017type}
we have started from an example
of a scope-and-type safe language (the simply typed $\lambda$-calculus), have studied
common invariant preserving traversals and noticed their similarity.
After introducing a notion of semantics and refactoring these traversals as
instances of the same fundamental lemma, we have observed the tight
connection between the abstract definition of semantics and the shape of the
language.

By extending a universe of datatype descriptions to support a notion of binding,
we have given a generic presentation of syntaxes with binding as well
as a large class of scope-and-type safe generic programs acting on all of them:
from renaming and substitution, to normalisation by evaluation, and the desugaring
of new constructors added by a language transformer. The code accompanying the
paper also demonstrates how to generically write a printer or a scope-checker
elaborating values of a raw syntax using strings as variable names into scope-safe
ones.

We have seen how to construct generic proofs about these generic programs. We
first introduced a Simulation relation showing what it means for two semantics
to yield related outputs whenever they are fed related input environments. We
then built on our experience to tackle a more involved case: identifying a set
of constraints guaranteeing that two semantics run consecutively can be subsumed
by a single pass of a third one.

We have put all of these results into practice by using them to solve the (to be
published) POPLMark Reloaded challenge which consists of formalising strong
normalisation for the simply typed $\lambda$-calculus via a logical-relation
argument. This also gave us the opportunity to try our framework on larger
languages by tackling the challenge's extensions to sum types and G\"{o}del's
System T.

Finally, we have demonstrated that this formalisation can be re-used
in other domains by seeing our syntaxes with binding as potentially cyclic
terms. Their unfolding is a non-standard semantics and we provide the
user with a generic notion of bisimilarity to reason about them.

% \subsection{Future work}

The diverse influences leading to this work suggest many opportunities
for future research.

Our example of the elaboration of an enriched language to a core one, and ACMM's
implementation of a Continuation Passing Style conversion function raises the question
of how many such common compilation passes can be implemented generically.

An extension of McBride's theory of ornaments~\citeyear{mcbride2010ornamental}
could provide an appropriate framework to highlight the connection between various
languages, some being seen as refinements of others. This is particularly
evident when considering the informative typechecker (see the accompanying
code) which given a scoped term produces a scoped-and-typed term by
type-checking or type-inference.

Our work on the POPLMark Reloaded challenge highlights a need for generic
notions of congruence closure which would come with guarantees (if the original
relation is stable under renaming and substitution so should the closure).
Similarly, the ``evaluation contexts'' corresponding to a syntax could be
derived automatically by building on the work of Huet~\citeyear{huet_1997}
and Abbott, Altenkirch, McBride and Ghani~\citeyear{abbott2005data}, 
allowing us to revisit previous work based on concrete instances of
ACMM such as McLaughlin, McKinna and Stark~\citeyear{craig2018triangle}.

Finally, now knowing how to generically describe syntaxes and their
well behaved semantics, we can start asking what it means to define
well behaved judgments. Why stop at helping the user write their specific
language's meta-theory when we could study meta-meta-theory?