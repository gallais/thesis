%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% SCOPE SAFE TERMS


\section{A Primer on Scope And Sort Safe Terms}\label{section:primer-term}

Scope safe terms follow the discipline that every variable is
either bound by some binder or is explicitly accounted for in a
context. Bellegarde and Hook~\citeyear{BELLEGARDE1994287}, Bird and Patterson~\citeyear{bird_paterson_1999},
and Altenkirch and Reus~\citeyear{altenkirch1999monadic} introduced the
classic presentation of scope safety using inductive
\emph{families}~\cite{dybjer1994inductive} instead of inductive types to
represent abstract syntax. Indeed, using a family indexed by a $\Set{}$,
we can track scoping information at the type level. The empty $\Set$ represents the empty scope. The functor
$1 + (\_)$ extends the running scope with an extra variable.

An inductive type is the fixpoint of an endofunctor on $\Set{}$.
Similarly, an inductive family is the fixpoint of an endofunctor on
$\Set \to \Set$. Using inductive families to enforce scope safety, we
get the following definition of the untyped $\lambda$-calculus: $T(F)
= \lambda X \!\in\! \Set{}.\; X + (F(X) \times F(X)) + F(1 + X)$.
This endofunctor offers a choice of three constructors.  The first one
corresponds to the variable case; it packages an inhabitant of $X$,
the index $\Set{}$. The second corresponds to an application node;
both the function and its argument live in the same scope as the
overall expression. The third corresponds to a $\lambda$-abstraction;
it extends the current scope with a fresh variable.  The language is
obtained as the fixpoint of $T$:
\[
   \mathit{Lam} = \mu F \in \Set{}^{\Set{}}.
   \lambda X \!\in\! \Set{}.\; X + (F(X) \times F(X)) + F(1 + X)
\]
Since `Lam' is a endofunction on Set, it makes
sense to ask whether it is also a functor and a monad. Indeed it is,
as Altenkirch and Reus have shown. The functorial action corresponds
to renaming, the monadic `return' corresponds to the use of variables,
and the monadic `join' corresponds to substitution. The functor and
monad laws correspond to well known properties from the equational
theories of renaming and substitution. We will revisit these properties
below in Section~\ref{section:fusion}.

\paragraph{A Mechanized Typed Variant of Altenkirch and Reus' Calculus.}\label{section:mech-reus}

There is no reason to restrict this technique to fixpoints of endofunctors
on $\Set{}^{\Set{}}$. The more general
case of fixpoints of (strictly positive) endofunctors on $\Set{}^J$ can be
endowed with similar operations by using Altenkirch, Chapman and
Uustalu's relative monads~\citeyear{Altenkirch2010, JFR4389}.

We pick as our $J$ the category whose objects are inhabitants of
\AD{List} \AB{I} (\AB{I} is a parameter of the construction) and whose morphisms are
thinnings (see Section~\ref{def:thinning}).  This \AD{List} \AB{I} is
intended to represent the list of the sort (/ kind / types depending
on the application) of the de Bruijn variables in scope. We can
recover an untyped approach by picking $I$ to be the unit type.  Given
this typed setting, our functors take an extra $I$ argument
corresponding to the type of the expression being built. This is
summed up by the large type \AB{I}
\AF{─Scoped}:% = $I$ $\to$ \AD{List} $I$ $\to$ \AF{Set}.

\begin{center}
\ExecuteMetaData[var.tex]{scoped}
%\caption{Type of Well \AB{I}-Kinded and Well Scoped Families}
\end{center}



%\begin{center}
\begin{minipage}[t]{0.35\textwidth}
\ExecuteMetaData[var.tex]{var}
\end{minipage}\hfill
\begin{minipage}[t]{0.55\textwidth}
\ExecuteMetaData[motivation.tex]{tm}
\end{minipage}
%\caption{Scope Aware Variables and Simply Typed $\lambda$-Terms\label{scoped-untyped}}
%\end{center}

The \AD{Type} \AF{─Scoped} family \AD{Lam} is Altenkirch
and Reus' simply typed $\lambda$-calculus representation. 




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% RELATED WORK

\section{Related Work}\label{section:related-work}

\subsection{Variable Binding} The representation of variable binding
in formal systems has been a hot topic for decades. Part of the purpose
of the first POPLMark challenge~\citeyear{poplmark} was to explore and
compare various methods.

Having based our work on a de Bruijn encoding of variables, and thus a
canonical treatment of \(\alpha\)-equivalence classes, our work has no
direct comparison with permutation-based treatments such as those of
Pitts' and Gabbay's nominal syntax~\cite{gabbay:newaas-jv}.

Our generic universe of syntax is based on
scope-and-typed de Bruijn indices~\cite{de1972lambda} but it is not
a necessity. It is for instance possible to give an interpretation
of \AD{Desc}riptions corresponding to Chlipala's Parametric Higher-Order
Abstract Syntax~\citeyear{chlipala2008parametric} and we would be interested
to see what the appropriate notion of Semantics is for this representation.

\subsection{Alternative Binding Structures} The binding structure we
present here is based on a flat, lexical scoping strategy. There are
other strategies and it would be interesting to see whether
our approach could be reused in these cases.

Bach Poulsen, Rouvoet, Tolmach, Krebbers and Visser~\citeyear{BachPoulsen}
introduce notions of scope graphs and frames to scale the techniques typical
of well scoped and typed deep embeddings to imperative languages. They can
already handle a large subset of Middleweight Java.

We have demonstrated how to write generic programs over the potentially
cyclic structures of Ghani, Hamana, Uustalu and Vene~\citeyear{ghani2006representing}.
Further work by Hamana~\citeyear{Hamana2009} yielded a different presentation
of cyclic structures which preserves sharing: pointers can not only refer
to nodes above them but also across from them in the cyclic tree. Capturing
this class of inductive types as a set of syntaxes with binding and writing
generic programs over them is still an open problem.

\subsection{Semantics of Syntaxes with Binding} An early foundational study
of a general \emph{semantic} framework for signatures with binding, algebras
for such signatures, and initiality of the term algebra, giving rise to a
categorical `program' for substitution and proofs of its properties, was given
by Fiore, Plotkin and Turi~\cite{FiorePlotkinTuri99}, working in the category of presheaves
over renamings, (a skeleton of) the category of finite sets. The presheaf
condition corresponds to our notion of being \AF{Thinnable}. Exhibiting
algebras based on both de Bruijn \emph{level} and \emph{index} encodings,
their approach isolates the usual (abstract) arithmetic required of such encodings.

By contrast, working in an \emph{implemented} type theory, where the encoding
can be understood as its own foundation, without appeal to an external mathematical
semantics, we are able to go further in developing machine-checked such
implementations and proofs, themselves generic with respect to an abstract syntax
\AD{Desc} of syntaxes-with-binding. Moreover, the usual source of implementation
anxiety, namely concrete arithmetic on de Bruijn indices, has been successfully
encapsulated via the \AF{□} coalgebra structure. It is perhaps noteworthy that
our type-theoretic constructions, by contrast with their categorical ones,
appear to make fewer commitments as to functoriality, thinnability, etc. in our
specification of semantics, with such properties typically being \emph{provable}
as a further instance of our framework.

\subsection{Meta-Theory Automation via Tactics and Code Generation} The
tediousness of repeatedly
proving similar statements has unsurprisingly led to various attempts at
automating the pain away via either code generation or the definition of
tactics. These solutions can be seen as untrusted oracles driving the
interactive theorem prover.

Polonowski's DBGen~\citeyear{polonowski:db} takes as input a raw syntax with
comments annotating binding sites. It generates a module defining lifting,
substitution as well as a raw syntax using names and a validation function
transforming named terms into de Bruijn ones; we refrain from calling it a
scopechecker as terms are not statically proven to be well scoped.

Kaiser, Schäfer, and Stark~\citeyear{Kaiser-wsdebr} build on our previous paper
to draft possible theoretical foundations for Autosubst, a so-far untrusted
set of tactics. The paper is based on a specific syntax: well-scoped call-by-value
System F. In contrast, our effort has been here to carve out
a precise universe of syntaxes with binding and give a systematic account
of their semantics and proofs.

Keuchel, Weirich, and Schrijvers' Needle~\citeyear{needleandknot} is a code
generator written in Haskell producing syntax-specific Coq modules
implementing common traversals and lemmas about them.

\subsection{Universes of Syntaxes with Binding} Keeping in mind Altenkirch
and McBride's observation that generic programming is everyday programming
in dependently-typed languages~\citeyear{genericprogramming-dtp}, we can naturally
expect generic, provably sound, treatments of these notions in tools such as
Agda or Coq.

Keuchel, Weirich, and Schrijvers' Knot~\citeyear{needleandknot} implements
as a set of generic programs the traversals and lemmas generated in specialised
forms by their Needle program. They see Needle as a pragmatic choice: working
directly with the free monadic terms over finitary containers would be too cumbersome. In
our experience solving the POPLMark Reloaded challenge, Agda's pattern
synonyms~\cite{Pickering:patsyn} make working with an encoded definition almost
seamless.

The GMeta generic framework~\citeyear{gmeta} provides a universe of syntaxes
and offers various binding conventions (locally nameless~\cite{Chargueraud2012}
or de Bruijn indices). It also generically implements common traversals (e.g. computing
the sets of free variables,
% measuring the size of a term,
shifting
de Bruijn indices or substituting terms for parameters) as well as common
predicates (e.g. being a closed term) and provides generic lemmas proving that
they are well behaved. It does not offer a generic framework
for defining new well scoped-and-typed semantics and proving their properties.

Érdi~\citeyear{gergodraft} defines a universe inspired by a first draft of this
paper and gives three different interpretations (raw, scoped and typed syntax)
related via erasure. He provides scope-and-type
preserving renaming and substitution as well as various generic proofs that
they are well behaved but offers neither a generic notion of semantics, nor
generic proof frameworks.

Copello~\citeyear{copello2017} works with \emph{named} binders and
defines nominal techniques (e.g. name swapping) and ultimately $\alpha$-equivalence
over a universe of regular trees with binders inspired by Morris'~\citeyear{morris-regulartt}.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% CONCLUSION

\section{Conclusion and Future Work}


% \subsection{Future work}


Finally, now knowing how to generically describe syntaxes and their
well behaved semantics, we can start asking what it means to define
well behaved judgments. Why stop at helping the user write their specific
language's meta-theory when we could study meta-meta-theory?