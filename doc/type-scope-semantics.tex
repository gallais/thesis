\chapter{Refactoring Common Traversals}

A programmer implementing an embedded language with bindings has a
wealth of possibilities. However, should she want to be able to inspect
the terms produced by her users in order to optimise or even compile
them, she will have to work with a deep embedding. Which means that she
will have to (re)implement a great number of traversals doing such
mundane things as renaming, substitution, or partial evaluation.
Should she want to get help from the typechecker in order to fend
off common bugs, she can opt for inductive families~\cite{dybjer1991inductive}
to enforce precise invariants. But the traversals now have to be
invariant preserving too!

\section{McBride's Kit}

In an unpublished manuscript, McBride~(\citeyear{mcbride2005type})
observes the similarity between the types and implementations of
renaming and substitution for the simply typed $λ$-calculus (ST$λ$C) in a
dependently typed language as shown in \cref{ren}. There are three
differences between the implemenations of renaming and substitution:
\begin{enumerate}
  \item
    in the variable case, after renaming a variable we must wrap it
    in a \AIC{`var} constructor whereas a substitution directly
    produces a term;
  \item
    when weakening a renaming to push it under a $λ$ we need only
    post-compose the remaning with the De Bruijn variable successor
    constructor \AIC{s} (which is essentially weakening for variables)
    whereas for a substitution we need a weakening operation for terms.
    It can be given by renaming via the successor constructor
    (\AF{ren} (\AIC{pack} \AIC{s}));
  \item
    also in the $λ$ case, when pushing a renaming or a substitution under
    a binder we must extend it to ensure that the variable bound by the
    $λ$ is mapped to itself. For renaming this involves its extension by
    the zeroth variable \AIC{z} whereas for subsitutions we must extend by
    the zeroth variable seen as a term (\AIC{`var} \AIC{z}).
\end{enumerate}

\begin{figure}[h]
\ExecuteMetaData[type-scope-semantics/StateOfTheArt/McBride05.tex]{ren}
\ExecuteMetaData[type-scope-semantics/StateOfTheArt/McBride05.tex]{sub}
\caption{Renaming\label{ren} and Substitution\label{sub} for the ST$λ$C}
\end{figure}

McBride then defines a notion of ``Kit'' abstracting these differences.
Rather than considering \AD{Var} and \AD{Tm} in isolation as different
types of environment values, he considers \AB{⧫}, an arbitrary
(\AD{Type} \AR{−Scoped}) and designs three constraints:

\begin{enumerate}
  \item
    One should be able to turn any environment value into a term of
    the same type and defined in the same scope (\ARF{var});
  \item
    One should be able to craft a fresh environment value associated
    to the zeroth variable of a scope (\ARF{zro});
  \item
    One should be able to embed environment values defined in a given
    scope into ones in a scope extended with a fresh variable (\ARF{wkn}).
\end{enumerate}

\begin{figure}[h]
\ExecuteMetaData[type-scope-semantics/StateOfTheArt/McBride05.tex]{kitdef}
\caption{\AR{Kit} as a set of constraints on \AB{⧫}}
\end{figure}

Whenever these constraints are met we can define a type and scope preserving
traversal which is based on an environment of \AB{⧫}-values. This is the
fundamental lemma of \AR{Kit}s:

\begin{figure}[h]
\ExecuteMetaData[type-scope-semantics/StateOfTheArt/McBride05.tex]{kitsem}
\caption{Fundamental lemma of \AR{Kit}}
\end{figure}

Unsurprisingly, we can recover renaming and substitution as two instances
of this fundamental lemma. We spell out the two \AR{Kit}s in~\cref{rensubkits}. The careful
reader will notice that, just like we needed \AF{ren} to define \AF{sub},
we need \AF{ren} to define the \AR{Kit} for substitution. This is not an
issue as we can instantiate the fundamental lemma a first time with
\AF{ren\textasciicircum{}Kit} before defining \AF{sub\textasciicircum{}Kit}.

\begin{figure}[h]
\begin{minipage}{0.5\textwidth}
  \ExecuteMetaData[type-scope-semantics/StateOfTheArt/McBride05.tex]{renkit}
\end{minipage}
\begin{minipage}{0.5\textwidth}
  \ExecuteMetaData[type-scope-semantics/StateOfTheArt/McBride05.tex]{subkit}
\end{minipage}
\caption{Renaming and Substitution as \AR{Kit}s\label{rensubkits}}
\end{figure}

\section{Opportunities for Further Generalizations}

After noticing that renaming and substitution fit the pattern, it is
natural to wonder about other traversals.

The evaluation function used in normalization by evaluation, although
not fitting \emph{exactly} in the \AR{Kit}-based approach, relies on
the same general structure. The variable case is nothing more than a
lookup in the environment; the application case is defined by combining
the results of two structural calls; and the lambda case corresponds to
the evaluation of the lambda's body in an extended context provided that
we can get a value for the newly-bound variable. Ignoring for now the
definitions of \AF{APP} and \AF{LAM}, we can see the similarities
in~\cref{nbe}.

\begin{figure}[h]
\ExecuteMetaData[type-scope-semantics/StateOfTheArt/McBride05.tex]{nbe}
\caption{Normalisation by Evaluation for the ST$λ$C\label{nbe}}
\end{figure}

\subsection{Outline} Building on this observation, our contributions
here are twofold:

\begin{itemize}
  \item
    We generalise the ``Kit'' approach from syntax to semantics bringing
    operations like normalisation by evaluation (cf.~\cref{nbe}) but also
    printing with a name supply, or continutation passing style translation
    into our framework.

  \item
    We prove generic results about simulations between and fusions of
    semantics given by, and enabled by, Kit.
\end{itemize}

We start by defining the simple calculus we will
use as a running example. We then introduce a notion of environments
and one well known instance: the category of renamings. This leads us
to defining a generic notion of type and scope-preserving Semantics
together with a generic evaluation function. We then showcase the
ground covered by these Semantics: from the syntactic ones
corresponding to renaming and substitution to printing with names,
variations of Normalisation by Evaluation or CPS transformations.
Finally, given the generic
definition of Semantics, we can prove fundamental lemmas about these
evaluation functions: we characterise the semantics which can simulate
one another and give an abstract treatment of composition yielding
compaction and reuse of proofs compared to Benton et
al.~(\citeyear{benton2012strongly}).

\section{The Calculus and Its Embedding}


\[
\begin{array}{lcl}
⟨\type{}⟩ & ::=    & \unit{} \\
          & \mid{} & \bool{} \\
          & \mid{} & \arrow{⟨\type{}⟩}{⟨\type{}⟩}
\end{array}
\]
