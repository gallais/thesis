\chapter{Variations on Normalisation by Evaluation}

Normalisation by Evaluation (NBE) is a technique leveraging the computational
power of a host language in order to normalise expressions of a deeply
embedded one. The process is based on a model construction describing a
family of types by induction on its \AF{Type} index. Two
procedures are then defined: the first (\AF{eval}) constructs an element
of \AB{ùìí} \AB{œÉ} \AB{Œì} provided a well typed term of the corresponding
\AD{Term} \AB{œÉ} \AB{Œì} type whilst the second (\AF{reify}) extracts, in
a type-directed manner, normal forms \AD{Nf} \AB{œÉ} \AB{Œì} from elements
of the model \AB{ùìí} \AB{œÉ} \AB{Œì}. NBE composes the two procedures. The
definition of this \AF{eval} function is a natural candidate for our
\AF{Semantics} framework. NBE is always defined \emph{for} a
given equational theory; we start by recalling the various
rules a theory may satisfy.

\subsection{Reduction Rules}

Thanks to \AF{Renaming} and \AF{Substitution} respectively, we can formally
define Œ∑-expansion and Œ≤-reduction. The Œ∑-rules say that for some types,
terms have a canonical form: functions will all be Œª-headed whilst records will
collect their fields -- here this makes all elements of \AIC{\unit{}} equal to \AIC{`one}.

\todo{insert definition of eta}

\begin{figure}[h]
\begin{mathpar}
\inferrule{\AB{t} ~\AS{:}~ \AD{Term}~ (\AB{œÉ} ~\AIC{`‚Üí}~ \AB{œÑ})~ \AB{Œì}
  }{\AB{t} \leadsto{} \AF{eta}~\AB{t}
  }{Œ∑_1}
\and \inferrule{\AB{t} ~\AS{:}~ \AD{Term}~ \AIC{`Unit}~ \AB{Œì}
  }{\AB{t} \leadsto{} \AIC{`one}
  }{Œ∑_2}
\and
\inferrule{
  }{\AIC{`app} ~(\AIC{`lam}~\AB{t})~ \AB{u} \leadsto \AB{t}~ \AF{‚ü®}~ \AB{u} ~\AF{/0‚ü©}
  }{Œ≤}
\end{mathpar}
\caption{Œ≤Œ∑ Rules for our Calculus\label{fig:betaetarules}}
\end{figure}

The Œ≤-rule is the main driver for actual computation,
but the presence of an inductive data type (\AIC{`Bool}) and its eliminator
(\AIC{`ifte}) means we have further redexes: whenever the
boolean the eliminator branches on is in canonical form, we may apply
a Œπ-rule. Finally, the Œæ-rule lets us reduce under
Œª-abstractions --- the distinction between weak-head normalisation and
strong normalisation.

\begin{figure}[h]
\begin{mathpar}
\inferrule{
  }{\AIC{`ifte}~\AIC{`tt}~\AB{l}~\AB{r} ~\leadsto{}~ \AB{l}
  }{Œπ_1}
\and
\inferrule{
  }{\AIC{`ifte}~\AIC{`ff}~\AB{l}~\AB{r} ~\leadsto{}~ \AB{r}
  }{Œπ_2}
\and
\inferrule{\AB{t} ~\leadsto{}~ \AB{u}
  }{\AIC{`lam}~ \AB{t} ~\leadsto{}~ \AIC{`lam}~\AB{u}
  }{Œæ}
\end{mathpar}
\caption{ŒπŒæ Rules for our Calculus\label{fig:iotaxirules}}
\end{figure}

Now that we have recalled all these rules, we can talk precisely about the
sort of equational theory decided by the model construction we choose to
perform. We start with the usual definition of NBE
which goes under Œªs and produces Œ∑-long Œ≤Œπ-short normal forms.

\subsection{Normal and Neutral Forms}

We parametrise the mutually defined inductive families \AD{Ne} and \AD{Nf}
by a predicate \AB{R} constraining the types at which one may embed a neutral
as a normal form. This constraint shows up in the type of \AIC{`neu}; it makes
it possible to control whether the NBE should Œ∑-expands all terms at certain
types by prohibiting the existence of neutral terms at said type.

\begin{figure}[h]
\ExecuteMetaData[type-scope-semantics.agda/Syntax/Normal.tex]{normal}
\caption{Neutral and Normal Forms}
\end{figure}

Once more, the expected notions of thinning \AF{th\textasciicircum{}Ne} and
\AF{th\textasciicircum{}Nf} are induced as \AD{Ne} and \AD{Nf} are syntaxes.
We omit their purely
structural implementation here and wish we could do so in source code,
too: our constructions so far have been syntax-directed and could
surely be leveraged by a generic account of syntaxes with binding.
We will tackle this problem in~\cref{a-universe}.

\section{Normalisation by Evaluation for Œ≤ŒπŒæŒ∑}
\label{normbye}

In the case of NBE, the environment values and the computations in the model
will both use the same type family \AF{Model}, defined by induction on the
\AD{Type} argument. The Œ∑-rules allow us to represent functions (respetively
inhabitants of \AIC{`Unit}) in the source language as function spaces
(respectively values of type \AR{‚ä§}). Evaluating a \AIC{`Bool} may however
yield a stuck term so we can't expect the model to give us anything more than
an open term in normal form.

The model construction then follows the usual pattern pioneered by
Berger~(\citeyear{berger1993program}) and formally analysed and thoroughly
explained by Catarina Coquand~(\citeyear{coquand2002formalised}). We work
by induction on the type and describe Œ∑-expanded values: all inhabitants
of (\AF{Model} \AIC{`Unit} \AB{Œì}) are equal and all elements
of (\AF{Model} (\AB{œÉ} \AIC{`‚Üí} \AB{œÑ}) \AB{Œì}) are functions in Agda.

\begin{figure}[h]
\ExecuteMetaData[type-scope-semantics.agda/Semantics/NormalisationByEvaluation/BetaIotaXiEta.tex]{model}
\caption{Model for Normalisation by Evaluation\label{fig:nbemodel}}
\end{figure}

This model is defined by induction on the type in terms either of
syntactic objects (\AD{Nf}) or using the \AF{‚ñ°}-operator which is
a closure operator for Thinnings. As such, it is trivial to prove
that for all type \AB{œÉ}, (\AF{Model} \AB{œÉ}) is \AF{Thinnable}.

\begin{figure}[h]
\ExecuteMetaData[type-scope-semantics.agda/Semantics/NormalisationByEvaluation/BetaIotaXiEta.tex]{thmodel}
\caption{Values in the Model are Thinnable\label{fig:thnbemodel}}
\end{figure}

Application's semantic counterpart is easy to define: given that \AB{ùì•}
and \AB{ùìí} are equal in this instance definition we can feed the argument
directly to the function, with the identity renaming. This corresponds to
\AF{extract} for the comonad \AF{‚ñ°}.

\begin{figure}[h]
\ExecuteMetaData[type-scope-semantics.agda/Semantics/NormalisationByEvaluation/BetaIotaXiEta.tex]{app}
\caption{Semantic Counterpart of \AIC{`app}\label{fig:nbeapp}}
\end{figure}

Conditional branching however is more subtle: the boolean value \AIC{`if} branches on
may be a neutral term in which case the whole elimination form is stuck. This forces
us to define \AF{reify} and \AF{reflect} first. These functions, also known as quote
and unquote respectively, give the interplay between neutral terms, model values and
normal forms. \AF{reflect} performs a form of semantic Œ∑-expansion: all stuck \AIC{`Unit}
terms are equated and all functions are Œª-headed. It allows us to define \AF{var0}, the
semantic counterpart of (\AIC{`var} \AIC{z}).

\begin{figure}[h]
\ExecuteMetaData[type-scope-semantics.agda/Semantics/NormalisationByEvaluation/BetaIotaXiEta.tex]{reifyreflect}
\caption{Reify and Reflect\label{fig:reifyreflectnbe}}
\end{figure}

We can then give the semantics of \AIC{`ifte}: if the boolean is a value, the
appropriate branch is picked; if it is stuck then the whole expression is stuck.
It is then turned into a neutral form by reifying the two branches and then reflected
in the model.

\begin{figure}[h]
\ExecuteMetaData[type-scope-semantics.agda/Semantics/NormalisationByEvaluation/BetaIotaXiEta.tex]{ifte}
\caption{Semantic Counterpart of \AIC{`ifte}\label{fig:nbeifte}}
\end{figure}

We can then combine these components. The semantics of a Œª-abstraction is simply the
identity function: the structure of the functional case in the definition of the model
matches precisely the shape expected in a \AF{Semantics}. Because the environment
carries model values, the variable case is trivial.

\begin{figure}[h]
\ExecuteMetaData[type-scope-semantics.agda/Semantics/NormalisationByEvaluation/BetaIotaXiEta.tex]{eval}
\caption{Evaluation is a \AR{Semantics}\label{fig:evalnbe}}
\end{figure}

We can define a normaliser by kickstarting the evaluation with an environment of
placeholder values obtained by reflecting the term's free variables and then reifying
the result.

\begin{figure}[h]
\ExecuteMetaData[type-scope-semantics.agda/Semantics/NormalisationByEvaluation/BetaIotaXiEta.tex]{norm}
\caption{Normalisation as Reification of an Evaluated Term\label{fig:normnbe}}
\end{figure}

\section{Normalisation by Evaluation for Œ≤ŒπŒæ}

As seen above, the traditional typed model construction leads to an NBE
procedure outputting Œ≤Œπ-normal Œ∑-long terms. However actual proof systems
rely on evaluation strategies that avoid applying Œ∑-rules
as much as possible: unsurprisingly, it is a rather bad idea to Œ∑-expand proof
terms which are already large when typechecking complex developments.

In these systems, normal forms are neither Œ∑-long nor Œ∑-short: the Œ∑-rule is
never deployed except when comparing a neutral and a constructor-headed term
for equality. Instead of declaring
them distinct, the algorithm does one step of Œ∑-expansion on the
neutral term and compares their subterms structurally. The conversion test
fails only when confronted with neutral terms with distinct head
variables or normal forms with different head constructors.

To reproduce this behaviour, NBE must be amended.
It is possible to alter the model definition described earlier so that it
avoids unnecessary Œ∑-expansions. We proceed by enriching the traditional
model with extra syntactical artefacts in a manner reminiscent of Coquand
and Dybjer's~(\citeyear{CoqDybSK}) approach to defining an NBE procedure for the SK combinator calculus. Their resorting to glueing
terms to elements of the model was dictated by the sheer impossibily to write
a sensible reification procedure but, in hindsight, it provides us with a
powerful technique to build models internalizing alternative equational
theories.

This leads us to using a predicate \AF{R} which holds for all types thus allowing
us to embed all neutrals into normal forms, and to  mutually defining the model
(\AF{Model}) together with the \emph{acting} model (\AF{Value}).

\begin{figure}[h]
\ExecuteMetaData[type-scope-semantics.agda/Semantics/NormalisationByEvaluation/BetaIotaXi.tex]{model}
\caption{Model Definition for Œ≤ŒπŒæ\label{nbestuckmodel}}
\end{figure}

These mutual definitions allow us to make a careful distinction between values
arising from (non expanded) stuck terms and the ones wich are constructor headed
and have a computational behaviour associated to them. The values in the acting
model are storing these behaviours be it either actual proofs of \AF{‚ä§}, actual
\AIC{`Bool}eans or actual Agda functions depending on the type of the term. It is
important to note that the functions in the acting model have the model as both
domain and codomain: there is no reason to exclude the fact that either the argument
or the body may or may not be stuck.

\ExecuteMetaData[type-scope-semantics.agda/Semantics/NormalisationByEvaluation/BetaIotaXi.tex]{thmodel}

What used to be called reflection in the previous model is now trivial:
stuck terms are indeed perfectly valid model values. Reification becomes
quite straightforward too because no Œ∑-expansion is needed. When facing
a stuck term, we simply embed it in the set of normal forms. Even though
\AF{reify} may look like it is performing some Œ∑-expansions, it is not
the case: all the values in the acting model are notionally obtained
from constructor-headed terms.

\ExecuteMetaData[type-scope-semantics.agda/Semantics/NormalisationByEvaluation/BetaIotaXi.tex]{reifyreflect}

Most combinators acting on this model follow a pattern similar to their
counterpart's in the previous section. Semantic application is
more interesting: in case the function is a stuck term, we grow its
spine by reifying its argument; otherwise we have an Agda function ready
to be applied. We proceed similarly for the definition of the semantical
\AIC{`ifte} (omitted here). Altogether, we get another
normaliser which is, this time, \emph{not} producing Œ∑-long normal forms.

\ExecuteMetaData[type-scope-semantics.agda/Semantics/NormalisationByEvaluation/BetaIotaXi.tex]{app}

\todo{Discuss IFTE}

\ExecuteMetaData[type-scope-semantics.agda/Semantics/NormalisationByEvaluation/BetaIotaXi.tex]{ifte}

Finally, we have all the necessary components to show that evaluating
the term whilst not Œ∑-expanding all stuck terms is a perfectly valid
\AR{Semantics}. As usual, normalisation is defined by composing
reification and evaluation on a diagonal environment made of placeholders.

\ExecuteMetaData[type-scope-semantics.agda/Semantics/NormalisationByEvaluation/BetaIotaXi.tex]{norm}

\section{Normalisation by Evaluation for Œ≤Œπ}

The decision to apply the Œ∑-rule lazily can be pushed even further: one may
forgo using the Œæ-rule too and simply perform weak-head normalisation. This
drives computation only when absolutely necessary, e.g.
when two terms compared for equality have matching head constructors
and one needs to inspect these constructors' arguments to conclude.

For that purpose, we introduce an inductive family describing terms in weak-head
normal forms. Naturally, it is possible to define the corresponding thinnings
\AF{th\textasciicircum{}WHNE} and \AF{th\textasciicircum{}WHNF} as well as erasure
functions \AF{erase\textasciicircum{}WHNE} and \AF{erase\textasciicircum{}WHNF}
with codomain \AD{Term} (we omit their simple definitions here).

The model construction is much like the previous one except
that source terms are now stored in the model too. This means that
from an element of the model, one can pick either the reduced version
of the input term (i.e. a stuck term or the term's computational
content) or the original. We exploit this ability most
notably in reification where once we have obtained either a
head constructor or a head variable, no subterms need to
be evaluated.

\todo{Add model}

Thinnable, reflection, and reification can all be defined rather
straightforwardly based on the template provided by the previous
section. The application and conditional branching rules are more
interesting: one important difference with respect to the previous
subsection is that we do not grow the spine of a stuck term using
reified versions of its arguments but rather the corresponding
\emph{source} term thus staying true to the idea that we only head
reduce enough to expose either a constructor or a variable.

We can finally put together all of these semantic counterparts to
obtain a \AR{Semantics} corresponding to weak-head normalisation.
We omit the now self-evident definition of \AF{norm\textasciicircum{}Œ≤Œπ} as the
composition of evaluation and reification.
