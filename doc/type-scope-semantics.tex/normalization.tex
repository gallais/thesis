\chapter{Variations on Normalisation by Evaluation}
\label{sec:variationsnormalisation}

Normalisation by Evaluation (NBE) is a technique leveraging the computational
power of a host language in order to normalise expressions of a deeply
embedded one (\cite{berger1991inverse,berger1993program,CoqDybSK,coquand2002formalised}).
A classic evaluation function manipulates a term in a purely syntactic manner,
firing redexes one after the other until none is left. In comparison,
normalisation by evaluation is a semantic technique that translates a term
into a program in the host language, relying on the host language's evaluation
machinery to produce a value. The challenging aspect of this technique is twofold.
First, we need to pick a translation that retains enough information that we
may extract a normal form from the returned value. Second, we need to make sure
that our leveraging of the host language's evaluation machinery does decide the
equational theory we are interested in. In this chapter, we will consider different
equational theories and as a consequence different translations.

\subsection{Interface of a NBE Procedure}

The normalisation by evaluation process is based on a model construction
inspired by the logical predicates of normalisation proofs. It is essentially
the computational part of such proofs.

Such a construction starts by describing a family of types \AB{Model} by
induction on its \AF{Type} index. Two procedures are then defined: the
first (\AF{eval}) constructs an element of (\AB{Model} \AB{σ} \AB{Γ})
provided a well typed term of the corresponding (\AD{Term} \AB{σ} \AB{Γ})
type whilst the second (\AF{reify}) extracts, in a type-directed manner,
normal forms (\AD{Nf} \AB{σ} \AB{Γ}) from elements of the model
(\AB{Model} \AB{σ} \AB{Γ}). NBE composes the two procedures.

The definition of this \AF{eval} function is a natural candidate for our
\AF{Semantics} framework. We introduce in \cref{fig:nbeinterface}) an abstract
interface for NBE formalising this observation.
%
We will see in this chapter that the various variations on normalisation by
evaluation that we will consider can all be described as instances of this
\AR{NBE} interface.

The \AR{NBE} interface is parametrised by two (\AD{Type} \AR{─Scoped})
families: the notion of model values (\AB{Model}) and normal forms
(\AB{Nf}) specific to this procedure. The interface packages a \AR{Semantics}
working on the \AB{Model}, an embedding of variables into model values
and a reification function from model values to normal forms.

\begin{figure}[h]
\ExecuteMetaData[type-scope-semantics.agda/Semantics/NormalisationByEvaluation/Specification.tex]{recnbe}
\caption{\AR{NBE} interface}\label{fig:nbeinterface}
\end{figure}

From each \AR{NBE} instance we can derive a normalisation function turning
terms into normal forms. The \ARF{embed} constraint guarantees that we can
manufacture an environment of placeholder values in which to run our
\AR{Semantics} to obtain an \AF{eval} function. Composing this evaluation
function with the reification procedure yields the normalisation procedure.

\begin{figure}[h]
\begin{minipage}[t]{0.55\textwidth}
\ExecuteMetaData[type-scope-semantics.agda/Semantics/NormalisationByEvaluation/Specification.tex]{eval}
\end{minipage}\begin{minipage}[t]{0.35\textwidth}
\ExecuteMetaData[type-scope-semantics.agda/Semantics/NormalisationByEvaluation/Specification.tex]{nbe}
\end{minipage}
\caption{Evaluation and normalisation functions derived from \AR{NBE}}\label{fig:nbeinterface}
\end{figure}

As we have explained earlier, NBE is always defined \emph{for} a given
equational theory. We start by recalling the various rules a theory may
satisfy.

\subsection{Reduction Rules}

We characterise an equational theory by a set of reduction rules. The
equational theory is obtained by taking the congruence closure of these
reduction rules under all term constructors except for λ-abstraction.
Indeed, we will consider systems with and without reductions under
λ-abstractions and can only make this distinction if using the congruence
rule for λ (usually called ξ) is made explicit.

\paragraph{Computation rules} Our first set of rules describes the kind
of computations we may expect. The β rule states that functions applied
to their argument may fire. It is the main driver for actual computation,
but the presence of an inductive data type and its eliminator means we
have further redexes: the ι rules specify that if-then-else conditionals
applied to concrete booleans may return the appropriate branch.

\begin{figure}[h]
\begin{mathpar}
  \inferrule
      { }
      {(λx. t) u ↝ t [u / x]}
      {β}
\end{mathpar}
\begin{mathpar}
  \inferrule
      { }
      {\mathtt{if ~true~ then~} l \mathtt{~else~} r \leadsto l}
      {ι_1}
  \and
  \inferrule
      { }
      {\mathtt{if~ false~ then~} l \mathtt{~else~} r \leadsto r}
      {ι_2}
\end{mathpar}
\caption{Computation rules: β and ι reductions}\label{fig:betaiotarules}
\end{figure}

\paragraph{Canonicity rules} The η-rules say that for some types, terms
have a canonical form: functions will all be λ-headed whilst records will
collect their fields -- here this makes all elements of the unit type equal
to \texttt{one}.

\begin{figure}[h]
\begin{mathpar}
\inferrule{Γ ⊢ t : σ → τ
  }{t \leadsto{} λx.t\,x
  }{η_1}
\and \inferrule{Γ ⊢ t : \mathtt{Unit}
  }{t \leadsto{} \mathtt{one}
  }{η_2}
\end{mathpar}
\caption{Canonicity rules: η rules for function and unit types\label{fig:etarules}}
\end{figure}

\paragraph{Congruence rule} Congruence rules are necessary if we do not
want to be limited to only computing whenever the root of the term happens
to already be a reducible expression. By deciding which ones are included,
we can however control the evaluation strategy of our calculus. We will
study the impact of the ξ-rule lets us reduce under λ-abstractions --- the
distinction between \emph{weak-head} normalisation and \emph{strong} normalisation.

\begin{figure}[h]
\begin{mathpar}
\inferrule{t ~\leadsto{}~ u
  }{λx.t ~\leadsto{}~ λx.u
  }{ξ}
\end{mathpar}
\caption{Congruence rule: ξ for strong normalisation\label{fig:xirules}}
\end{figure}

Now that we have recalled all these rules, we can talk precisely about the
sort of equational theory decided by the model construction we choose to
perform. The last piece of the puzzle we will need before writing our first
evaluator is a notion of normal form.

\subsection{Normal and Neutral Forms}

The inductive family of normal forms characterises irreducible terms for a
given set of reduction rules. It is mutually defined with the family of
neutral terms that characterises stuck computations i.e. a variable with
a spine of eliminators (here applications or if-then-else conditionals).

We parametrise these mutually defined inductive families \AD{Ne} and \AD{Nf}
by a predicate \AB{NoEta} constraining the types at which one may embed a neutral
as a normal form. This constraint shows up in the type of \AIC{`neu}; it makes
it possible to control whether the NBE should η-expands all terms at certain
types by prohibiting the existence of neutral terms at said type.

\begin{figure}[h]
\ExecuteMetaData[type-scope-semantics.agda/Syntax/Normal.tex]{normal}
\caption{Neutral and Normal Forms}
\end{figure}

Once more, the expected notions of thinning \AF{th\textasciicircum{}Ne} and
\AF{th\textasciicircum{}Nf} are induced as \AD{Ne} and \AD{Nf} are syntaxes.
We omit their purely
structural implementation here and wish we could do so in source code,
too: our constructions so far have been syntax-directed and could
surely be leveraged by a generic account of syntaxes with binding.
We will tackle this problem in~\cref{a-universe}.

We start with a standard strong evaluator i.e. an evaluator implementing
\emph{strong} normalisation in the sense that it goes under λ-abstractions.
This kind of evaluator is used for instance in Coq
(\cite{DBLP:conf/icfp/GregoireL02,DBLP:conf/cpp/BoespflugDG11})
although the focus there is different: the host language (OCaml)  is not
total, evaluation is untyped, and unsafe features are used to maximise
the evaluator's performance.

\input{type-scope-semantics.tex/normalization/betaiotaxi.tex}

\input{type-scope-semantics.tex/normalization/betaiotaxieta.tex}
\input{type-scope-semantics.tex/normalization/betaiota.tex}
