\chapter{Generic Scope Safe and Well Kinded Programs for Syntaxes}\label{chapter:generic-semantics}

The set of constraints we called a \AR{Semantics} in \cref{section:generic-semantics}
for the specific example of the simply typed λ-calculus could be divided in two groups:
the one arising from the fact that we need to be able to push environment values under
binders and the ones in one-to-one correspondence with constructors for the language.

Based on this observation, we can define a generic notion of semantics for all syntax
descriptions. It is once more parametrised by two (\AB{I}\AF{─Scoped}) families \AB{𝓥}
and \AB{𝓒} corresponding respectively to values associated to bound variables and
computations delivered by evaluating terms.

\ExecuteMetaData[generic-syntax.agda/Generic/Semantics.tex]{semrec}

These two families have to abide by three constraints. First, values should be thinnable
so that we can push the evaluation environment under binders.

\ExecuteMetaData[generic-syntax.agda/Generic/Semantics.tex]{thv}

Second, values should embed into computations for us to be able to return the value
associated to a variable in the environment as the result of its evaluation.

\ExecuteMetaData[generic-syntax.agda/Generic/Semantics.tex]{var}

Third, we have a constraint similar to the one needed to define \AF{fold} in
\cref{section:data} (\cref{figure:datamu}). We should have an algebra taking
a term whose substructures have already been evaluated and returning a
computation for the overall term.

\ExecuteMetaData[generic-syntax.agda/Generic/Semantics.tex]{alg}

To make formal this idea of ``hav[ing] already been evaluated'' we crucially use
the fact that the meaning of a description is defined in terms of a function
interpreting substructures which has the type (\AF{List} \AB{I} \AS{→} \AB{I}\AF{─Scoped}),
i.e. that gets access to the current scope but also the exact list of the newly
bound variables' kinds.

We define a function \AF{Kripke} by case analysis on the number of newly bound
variables. It is essentially a subcomputation waiting for a value associated to
each one of the fresh variables. If it's $0$ we expect the substructure to be a
computation corresponding to the result of the evaluation function's recursive
call; but if there are newly bound variables then we expect to have a function
space. In any context extension, it will take an environment of values for the
newly-bound variables and produce a computation corresponding to the evaluation
of the body of the binder.

\ExecuteMetaData[shared/Data/Environment.tex]{kripke}

%The name \AF{Kripke} comes from the connection with the interpretation of
%implication in Kripke models where if something holds in one world, it holds
%in all successive ones.

It is once more the case that the abstract notion of Semantics comes with a
fundamental lemma: all \AB{I} \AF{─Scoped} families \AB{𝓥} and \AB{𝓒} satisfying
the three criteria we have put forward give rise to an evaluation function.
We introduce a notion of computation \AF{\_─Comp} analogous to that of environments:
instead of associating values to variables, it associates computations to terms.

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Semantics.tex]{comp}
\caption{\AF{\_─Comp}: Associating Computations to Terms}
\end{figure}

We can now define the type of the fundamental lemma (called \AF{semantics}) which
takes a semantics and returns a function from environments to computations. It is
defined mutually with a function \AF{body} turning syntactic binders into
semantics binders: to each de Bruijn \AF{Scope} (i.e. a substructure in a potentially
extended context) it associates a \AF{Kripke} (i.e. a subcomputation expecting a
value for each newly bound variable).

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Semantics.tex]{semtype}
\caption{Statement of the Fundamental Lemma of \AR{Semantics}}
\end{figure}

The proof of \AF{semantics} is straightforward now that we have clearly identified the
problem's structure and the constraints we need to enforce. If the term considered
is a variable, we lookup the associated value in the evaluation environment and
turn it into a computation using \ARF{var}. If it is a non variable constructor
then we call \AF{fmap} to evaluate the substructures using \AF{body} and then
call the \ARF{alg}ebra to combine these results.

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Semantics.tex]{semproof}
\caption{Proof of the Fundamental Lemma of \AR{Semantics} -- \AF{semantics}}
\end{figure}

The auxiliary lemma \AF{body} distinguishes two cases. If no new variable has
been bound in the recursive substructure, it is a matter of calling \AF{semantics}
recursively. Otherwise we are provided with a \AF{Thinning}, some additional
values and evaluate the substructure in the thinned and extended evaluation
environment thanks to a auxiliary function \AF{\_>>\_} which given two
environments {(\AB{Γ} \AR{─Env}) \AB{𝓥} \AB{Θ}} and {(\AB{Δ} \AR{─Env}) \AB{𝓥} \AB{Θ}}
produces an environment {((\AB{Γ} \AF{++} \AB{Δ}) \AR{─Env}) \AB{𝓥} \AB{Θ})}.

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Semantics.tex]{bodyproof}
\caption{Proof of the Fundamental Lemma of \AR{Semantics} -- \AF{body}\label{fig:genbody}}
\end{figure}

Given that \AF{fmap} introduces one level of indirection between the recursive
calls and the subterms they are acting upon, the fact that our terms are indexed
by a \AF{Size} is once more crucial in getting the termination checker to see
that our proof is indeed well founded.


Because most of our examples involve closed terms (for which we have introduced a special
notation in \cref{fig:closedtm}), we define a specialised of the fundamental lemma of semantics
for closed terms and apply it to the empty environment.

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Semantics.tex]{closed}
\caption{Special Case: Fundamental Lemma of \AR{Semantics} for Closed Terms\label{fig:closedsem}}
\end{figure}


\section{Our First Generic Programs: Renaming and Substitution}\label{section:renandsub}

Similarly to \cref{sec:syntactic} renaming and substitutions can be defined generically
for all syntax descriptions.

\paragraph{Renaming} is a semantics with \AF{Var} as values and \AD{Tm} as computations.
The first two constraints on \AF{Var} described earlier are trivially satisfied. Observing
that renaming strictly respects the structure of the term it goes through, it makes
sense for the algebra to be implemented using \AF{fmap}. When dealing with the body
of a binder, we `reify' the \AF{Kripke} function by evaluating it in an extended
context and feeding it placeholder values corresponding to the extra variables
introduced by that context. This is reminiscent both of what we did in
\cref{sec:syntactic} and the definition of reification in the setting of normalisation
by evaluation (see e.g. Coquand's work~\citeyear{coquand2002formalised}).

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Semantics/Syntactic.tex]{renaming}
\caption{Renaming: A Generic Semantics for Syntaxes with Binding\label{fig:genrensem}}
\end{figure}

From this instance, we can derive the proof that all terms are \AF{Thinnable} as
a corollary of the fundamental lemma of \AR{Semantics}.

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Semantics/Syntactic.tex]{thTm}
\caption{Corollary: Generic Thinning\label{fig:genren}}
\end{figure}

\paragraph{Substitution} is defined in a similar manner with \AD{Tm} as both values and computations.
Of the two constraints applying to terms as values, the first one corresponds to renaming
and the second one is trivial. The algebra is once more defined by using \AF{fmap} and
reifying the bodies of binders. We can, once more, obtain parallel substitution as a
corollary of the fundamental lemma of \AR{Semantics}.

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Semantics/Syntactic.tex]{substitution}
\ExecuteMetaData[generic-syntax.agda/Generic/Semantics/Syntactic.tex]{sub}
\caption{Generic Parallel Substitution for All Syntaxes with Binding\label{fig:gensub}}
\end{figure}

\paragraph{The reification process} mentioned in the definition of renaming and substitution
can be implemented generically for \AR{Semantics} families which have \AR{VarLike}
values (\AF{vl\textasciicircum{}Var} and \AF{vl\textasciicircum{}Tm} are proofs of
\AR{VarLike} for \AD{Var} and \AD{Tm} respectively) i.e. values which are thinnable
and such that we can craft placeholder values in non-empty contexts.

\begin{figure}[h]
\ExecuteMetaData[shared/Data/Var/Varlike.tex]{varlike}
\caption{\AR{VarLike}: \AF{Thinnable} and with placeholder values}
\end{figure}

For any \AR{VarLike} \AB{𝓥}, we can define \AF{fresh\textsuperscript{r}} of
type {((\AB{Γ} \AR{─Env}) \AB{𝓥} (\AB{Δ} \AF{++} \AB{Γ}))} and \AF{fresh\textsuperscript{l}} of
type {((\AB{Γ} \AR{─Env}) \AB{𝓥} (\AB{Γ} \AF{++} \AB{Δ}))} by combining the use
of placeholder values and thinnings. Hence, we can then write a generic \AF{reify}
(\cref{fig:kripkereify}) turning \AF{Kripke} function spaces from \AB{𝓥} to \AB{𝓒}
into \AF{Scope}s of \AB{𝓒} computations.

\begin{figure}[h]
\ExecuteMetaData[shared/Data/Var/Varlike.tex]{reify}
\caption{Generic Reification thanks to \AR{VarLike} Values\label{fig:kripkereify}}
\end{figure}

We can now showcase other usages by providing a catalogue of generic programs
for syntaxes with binding.

\section{Sugar and Desugaring as a Semantics}\label{section:letbinding}

One of the advantages of having a universe of programming language
descriptions is the ability to concisely define an \emph{extension}
of an existing language by using \AD{Desc}ription transformers
grafting extra constructors à la Swiestra~(\citeyear{swierstra_2008}).
This is made extremely simple by the
disjoint sum combinator \AF{\_`+\_} we defined in Section~\ref{desccomb}.
An example of such an extension is the addition of let-bindings to
an existing language.

Let bindings allow the user to avoid repeating themselves by naming
sub-expressions and then using these names to refer to the associated
terms. Preprocessors adding these types of mechanisms to existing
languages (from C to CSS) are rather popular. We introduce a
description of \AD{Let}-bindings which can be used to extend any
language description \AB{d} to \AB{d} \AF{`+} \AF{Let} (where \AF{`+}
is the disjoint of sum of two descriptions defined in Figure~\ref{figure:descsum}):

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Examples/ElaborationLet.tex]{letcode}
\caption{Description of a Single Let Binding}
\end{figure}

This description states that a let-binding node stores a pair of types
\AB{$\sigma$} and \AB{$\tau$} and two subterms. First comes the let-bound
expression of type \AB{$\sigma$} and second comes the body of the let which
has type \AB{$\tau$} in a context extended with a fresh variable of type
\AB{$\sigma$}. This defines a term of type \AB{$\tau$}.

In a dependently typed language, a type may depend on a value which
in the presence of let bindings may be a variable standing for an
expression. The user naturally does not want it to make any difference
whether they used a variable referring to a let-bound expression or
the expression itself. Various typechecking strategies can accommodate
this expectation: in Coq (\cite{Coq:manual}) let bindings are primitive
constructs of the language and have their own typing and reduction
rules whereas in Agda they are elaborated away to the core language
by inlining.

This latter approach to extending a language \AB{d} with let bindings
by inlining them before typechecking can be implemented generically as
a semantics over (\AB{d} \AF{`+} \AF{Let}). For this semantics values
in the environment and computations are both let-free terms. The algebra
of the semantics can be defined by parts thanks to \AF{case} defined in
\cref{desccomb}: the old constructors are kept the same by interpreting
them using the generic \AF{Substitution} algebra;
whilst the let-binder precisely provides the extra value to be added to the
environment.

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Examples/ElaborationLet.tex]{letelab}
\caption{\AF{Let}-Elaboration as a \AR{Semantics}}
\end{figure}

The process of removing let binders is kickstarted with a placeholder
environment associating each variable to itself.

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Examples/ElaborationLet.tex]{unlet}
\caption{Corollary: \AF{Let}-Elaboration via Evaluation with Placeholders}
\end{figure}

In half a dozen lines of code we have defined a generic extension of syntaxes with
binding together with a semantics which corresponds to an elaborator translating
away this new construct. We have seen in \cref{cps-transformation} that it is
similarly possible to implement a Continuation Passing Style transformation as
a semantics for STLC.

We have demonstrated how easily one can define extensions and combine them on top
of a base language without having to reimplement common traversals for each one
of the intermediate representations. Moreover, it is possible to define
\emph{generic} transformations elaborating these added features in terms of
lower-level ones. This suggests that this setup could be a good candidate to
implement generic compilation passes and could deal with a framework using a
wealth of slightly different intermediate languages à la Nanopass (\cite{Keep:2013:NFC:2544174.2500618}).


\section{(Unsafe) Normalisation by Evaluation}\label{section:unsafenbyeval}

A key type of traversal we have not studied yet is a language's evaluator. Our
universe of syntaxes with binding does not impose any typing discipline on the
user-defined languages and as such cannot guarantee their totality. This is
embodied by one of our running examples: the untyped $\lambda$-calculus. As a
consequence there is no hope for a safe generic framework to define normalisation
functions.

The clear connection between the \AF{Kripke} functional space characteristic of
our semantics and the one that shows up in normalisation by evaluation suggests
we ought to manage to give an unsafe generic framework for normalisation by evaluation.
By temporarily \textbf{disabling Agda's positivity checker}, we can define a
generic reflexive domain \AD{Dm} in which to interpret our syntaxes. It has three
constructors corresponding respectively to a free variable, a constructor's
counterpart where scopes have become \AF{Kripke} functional spaces on \AD{Dm}
and an error token because the evaluation of untyped programs may go wrong.

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Semantics/NbyE.tex]{domain}
\caption{Corollary: \AF{Let}-Elaboration via Evaluation with Placeholders}
\end{figure}

This datatype definition is utterly unsafe. The more conservative user will happily
restrict herself to typed settings where the domain can be defined as a logical
predicate or opt instead for a step-indexed approach. But this domain does make it
possible to define a generic \AF{nbe} semantics by only specifying an algebra to
evaluate one ``layer'' of term. This constraint is minimal: there is no way for
us to know a priori what a constructor means; a binder could represent
$\lambda$-abstractions, $\Sigma$-types, fixpoints, or anything else.

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Semantics/NbyE.tex]{alg}
\ExecuteMetaData[generic-syntax.agda/Generic/Semantics/NbyE.tex]{nbe}
\caption{Evaluation as a \AR{Semantics}}
\end{figure}

Thanks to the fact we have picked a universe of finitary syntaxes, we can
\emph{traverse} (\cite{mcbride_paterson_2008}) the functor to define a
(potentially failing) reification function turning elements of the reflexive
domain into terms. The Kripke function spaces can themselves be reified:
\AD{Dm} is \AR{VarLike} thanks to the \AIC{V} constructor.

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Semantics/NbyE.tex]{reify}
\caption{Generic Reification via \AF{sequenceA}}
\end{figure}

By composing them, we obtain the normalisation function which gives its name
to normalisation by evaluation: provided a term, we produce a value in the
reflexive domain by evaluating it in an environment made of placeholder values
and then reify it to a (maybe) term.

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Semantics/NbyE.tex]{norm}
\caption{Normalisation by Evaluation}
\end{figure}

\subsection{Example: Evaluator for the Untyped Lambda-Calculus}

Using this setup, we can write a normaliser for the untyped $\lambda$-calculus:
we use a pattern matching lambda to distinguish between the counterpart of the
$\lambda$-abstraction constructor on one hand and the application one on the other.
The former is trivial: functions are already values! The semantical counterpart of
application proceeds by case analysis on the function: if it corresponds
to a $\lambda$-abstraction, we can fire the redex by using the Kripke functional space;
otherwise we grow the spine of stuck applications.

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Examples/NbyE.tex]{norm}
\caption{Normalisation for the Untyped $\lambda$-calculus}
\end{figure}

We have not used the \AIC{⊥} constructor so \emph{if} the evaluation terminates
(by disabling the strict positivity check we have lost all guarantees of the sort)
we know we will get a term in normal form. For instance: identity applied twice
to itself yield a strongly normalising term and if we run the evaluator we indeed
get the identity as an output as demonstrated in \cref{fig:normid3}.

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Examples/NbyE.tex]{example}
\caption{Normalization Example\label{fig:normid3}}
\end{figure}


\section{Printing with Names, Generically}

Coming back to our work on (rudimentary) printing with names in \cref{prettyprint},
we can now give a generic account of it. This is a particularly interesting example
because it demonstrates that we may sometimes want to give \AD{Desc} a different
semantics to accommodate a specific use-case: we do not want our users to deal explicitly
with name generation, explicit variable binding, etc.

We are going to reuse some of the components defined in \cref{prettyprint}: we can
rely on the same state monad for name generation, the same \AF{fresh} function and
the same notions of \AF{Name} and \AF{Printer} for the semantics' values and
computations.

The first piece of the puzzle is \AF{Pieces}. The structure of \AR{Semantics} would
suggest giving our users an interface where sub-structures are interpreted as \AF{Kripke}
function spaces expecting fresh names for the fresh variables and returning a monadic
computation delivering a printer. However we can do better: we can preemptively generate
a set of fresh names for the newly-bound variables and hand them to the user together
with the result of printing the body with these names. As usual we have a special case
for the substructures without any newly-bound variable. Note that the specific target
context of the environment of \AF{Name}s is only picked for convenience as \AF{Name}
ignores the scope: ({\AB{Δ} \AF{++} \AB{Γ}}) is what \AF{freshˡ} gives us.

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Semantics/Printing]{pieces}
\caption{Interpretation of Recursive Substructures: Printing Pieces\label{fig:printingpieces}}
\end{figure}

The key component making this work is the reification function
\AF{reify\textasciicircum{}M} turning the \AF{Kripke} spaces we get from the semantics
framework into \AF{Pieces}. This function has to be monadic so that we may generate
fresh names. It uses the fact that environments are traversable and that
({\AF{M} \AF{Name}}) is easily proven to be \AF{VarLike} (\AF{fresh} generates new
names and they are trivially \AR{Thinnable} as they ignore their scope) to
generate an environment of names for the newly-bound variables.

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Semantics/Printing]{reifypieces}
\caption{Reification: from Kripke Functions to Pieces\label{fig:printingreify}}
\end{figure}

We also expect the user to provide us with a syntax-specific ({\AF{Display} \AB{d}})
explaining how to print one ``layer'' of term where the subterms are \AF{Pieces} i.e.
both the names of the variables bound in the subterms and the string representation of
the subterms are available. See \cref{sec:printingexample} for a concrete example of
such a \AF{Display}.

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Semantics/Printing]{display}
\caption{Syntax-Specific \AF{Display} Instructions\label{fig:printingdisplay}}
\end{figure}

Once we have these key components, we can write our printer as a \AR{Semantics}. The two
first constraints are trivial: \AR{Name} is constant in its scope argument and therefore
trivially thinnable and names (strings) are trivially printers (strings in the \AF{M}
monad). The algebra is trickier to define. But because we know how to convert \AF{Kripke}
function spaces from \AF{Name}s to \AF{Printer} into \AF{M}-wrapped \AF{Pieces} and
because the functor induced by a description is traversable, we can get a layer of
term where the subterms are \AF{Pieces}. It is then just a matter of applying the
user-supplied \AF{Display} directive to obtain a string representation of the term.

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Semantics/Printing]{printing}
\caption{Printing as a Generic Semantics\label{fig:genprinting}}
\end{figure}

Using the \AF{closed} version of the fundamental lemma of semantics defined in
\cref{fig:closedsem} and reusing the name supply defined in \cref{prettyprint}
we obtain a printer for closed terms.

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Semantics/Printing]{print}
\caption{Printer for closed terms\label{fig:genprinter}}
\end{figure}

\subsection{Example: Printing Terms of STLC}
\label{sec:printingexample}

Our only purpose here is to show how one typically defines a \AF{Display} to
define a printer. Remember that we get one ``layer'' of term as an input, in this
specific case it means either an application or a $\lambda$-abstraction. We use
a pattern-matching lambda to distinguish the two cases. If we have an application
then we have already been given a string \AB{f} for the function and \AB{t} for the
argument; we use Krivine's convention of writing $(f)t$ for the application. If we
have a $\lambda$-abstraction, it means we are handed a pair of a (singleton) environment
containing a fresh name \AB{x} for the variable bound by the lambda together with a
representation \AB{b} of the body using that name; we return $\lambda{}x.b$.

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Examples/Printing]{display}
\caption{Display Directive for STLC\label{fig:exampledisplay}}
\end{figure}

We can of course run the printer and check that it does produce the string we would
expect.

\ExecuteMetaData[generic-syntax.agda/Generic/Examples/Printing]{example}
