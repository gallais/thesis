\chapter{Generic Scope Safe and Well Kinded Programs for Syntaxes}\label{chapter:generic-semantics}

The set of constraints we called a \AR{Semantics} in \cref{section:generic-semantics}
for the specific example of the simply typed Œª-calculus could be divided in two groups:
the one arising from the fact that we need to be able to push environment values under
binders and the ones in one-to-one correspondence with constructors for the language.

Based on this observation, we can define a generic notion of semantics for all syntax
descriptions. It is once more parametrised by two (\AB{I}\AF{‚îÄScoped}) families \AB{ùì•}
and \AB{ùìí} corresponding respectively to values associated to bound variables and
computations delivered by evaluating terms.

\ExecuteMetaData[generic-syntax.agda/Generic/Semantics.tex]{semrec}

These two families have to abide by three constraints. First, values should be thinnable
so that we can push the evaluation environment under binders.

\ExecuteMetaData[generic-syntax.agda/Generic/Semantics.tex]{thv}

Second, values should embed into computations for us to be able to return the value
associated to a variable in the environment as the result of its evaluation.

\ExecuteMetaData[generic-syntax.agda/Generic/Semantics.tex]{var}

Third, we have a constraint similar to the one needed to define \AF{fold} in
\cref{section:data} (\cref{figure:datamu}). We should have an algebra taking
a term whose substructures have already been evaluated and returning a
computation for the overall term.

\ExecuteMetaData[generic-syntax.agda/Generic/Semantics.tex]{alg}

To make formal this idea of ``hav[ing] already been evaluated'' we crucially use
the fact that the meaning of a description is defined in terms of a function
interpreting substructures which has the type (\AF{List} \AB{I} \AS{‚Üí} \AB{I}\AF{‚îÄScoped}),
i.e. that gets access to the current scope but also the exact list of the newly
bound variables' kinds.

We define a function \AF{Kripke} by case analysis on the number of newly bound
variables. It is essentially a subcomputation waiting for a value associated to
each one of the fresh variables. If it's $0$ we expect the substructure to be a
computation corresponding to the result of the evaluation function's recursive
call; but if there are newly bound variables then we expect to have a function
space. In any context extension, it will take an environment of values for the
newly-bound variables and produce a computation corresponding to the evaluation
of the body of the binder.

\ExecuteMetaData[shared/Data/Environment.tex]{kripke}

%The name \AF{Kripke} comes from the connection with the interpretation of
%implication in Kripke models where if something holds in one world, it holds
%in all successive ones.

It is once more the case that the abstract notion of Semantics comes with a
fundamental lemma: all \AB{I} \AF{‚îÄScoped} families \AB{ùì•} and \AB{ùìí} satisfying
the three criteria we have put forward give rise to an evaluation function.
We introduce a notion of computation \AF{\_‚îÄComp} analogous to that of environments:
instead of associating values to variables, it associates computations to terms.

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Semantics.tex]{comp}
\caption{\AF{\_‚îÄComp}: Associating Computations to Terms}
\end{figure}

We can now define the type of the fundamental lemma (called \AF{semantics}) which
takes a semantics and returns a function from environments to computations. It is
defined mutually with a function \AF{body} turning syntactic binders into
semantics binders: to each de Bruijn \AF{Scope} (i.e. a substructure in a potentially
extended context) it associates a \AF{Kripke} (i.e. a subcomputation expecting a
value for each newly bound variable).

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Semantics.tex]{semtype}
\caption{Statement of the Fundamental Lemma of \AR{Semantics}}
\end{figure}

The proof of \AF{semantics} is straightforward now that we have clearly identified the
problem structure and the constraints we need to enforce. If the term considered
is a variable, we lookup the associated value in the evaluation environment and
turn it into a computation using \ARF{var}. If it is a non variable constructor
then we call \AF{fmap} to evaluate the substructures using \AF{body} and then
call the \ARF{alg}ebra to combine these results.

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Semantics.tex]{semproof}
\caption{Proof of the Fundamental Lemma of \AR{Semantics} -- \AF{semantics}}
\end{figure}

The auxiliary lemma \AF{body} distinguishes two cases. If no new variable has
been bound in the recursive substructure, it is a matter of calling \AF{semantics}
recursively. Otherwise we are provided with a \AF{Thinning}, some additional
values and evaluate the substructure in the thinned and extended evaluation
environment thanks to a auxiliary function \AF{\_>>\_} which given two
environments {(\AB{Œì} \AR{‚îÄEnv}) \AB{ùì•} \AB{Œò}} and {(\AB{Œî} \AR{‚îÄEnv}) \AB{ùì•} \AB{Œò}}
produces an environment {((\AB{Œì} \AF{++} \AB{Œî}) \AR{‚îÄEnv}) \AB{ùì•} \AB{Œò})}.

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Semantics.tex]{bodyproof}
\caption{Proof of the Fundamental Lemma of \AR{Semantics} -- \AF{body}}
\end{figure}

Given that \AF{fmap} introduces one level of indirection between the recursive
calls and the subterms they are acting upon, the fact that our terms are indexed
by a \AF{Size} is once more crucial in getting the termination checker to see
that our proof is indeed well founded.

\section{Our First Generic Programs: Renaming and Substitution}\label{section:renandsub}

Similarly to \cref{sec:syntactic} renaming and substitutions can be defined generically
for all syntax descriptions.

\paragraph{Renaming} is a semantics with \AF{Var} as values and \AD{Tm} as computations.
The first two constraints on \AF{Var} described earlier are trivially satisfied. Observing
that renaming strictly respects the structure of the term it goes through, it makes
sense for the algebra to be implemented using \AF{fmap}. When dealing with the body
of a binder, we `reify' the \AF{Kripke} function by evaluating it in an extended
context and feeding it placeholder values corresponding to the extra variables
introduced by that context. This is reminiscent both of what we did in
\cref{sec:syntactic} and the definition of reification in the setting of normalisation
by evaluation (see e.g. Coquand's work~\citeyear{coquand2002formalised}).

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Semantics/Syntactic.tex]{renaming}
\caption{Renaming: A Generic Semantics for Syntaxes with Binding\label{fig:genrensem}}
\end{figure}

From this instance, we can derive the proof that all terms are \AF{Thinnable} as
a corollary of the fundamental lemma of \AR{Semantics}.

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Semantics/Syntactic.tex]{thTm}
\caption{Corollary: Generic Thinning\label{fig:genren}}
\end{figure}

\paragraph{Substitution} is defined in a similar manner with \AD{Tm} as both values and computations.
Of the two constraints applying to terms as values, the first one corresponds to renaming
and the second one is trivial. The algebra is once more defined by using \AF{fmap} and
reifying the bodies of binders. We can, once more, obtain parallel substitution as a
corollary of the fundamental lemma of \AR{Semantics}.

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Semantics/Syntactic.tex]{substitution}
\ExecuteMetaData[generic-syntax.agda/Generic/Semantics/Syntactic.tex]{sub}
\caption{Generic Parallel Substitution for All Syntaxes with Binding\label{fig:gensub}}
\end{figure}

\paragraph{The reification process} mentioned in the definition of renaming and substitution
can be implemented generically for \AR{Semantics} families which have \AR{VarLike}
values (\AF{vl\textasciicircum{}Var} and \AF{vl\textasciicircum{}Tm} are proofs of
\AR{VarLike} for \AD{Var} and \AD{Tm} respectively) i.e. values which are thinnable
and such that we can craft placeholder values in non-empty contexts.

\begin{figure}[h]
\ExecuteMetaData[shared/Data/Var/Varlike.tex]{varlike}
\caption{\AR{VarLike}: \AF{Thinnable} and with placeholder values}
\end{figure}

For any \AR{VarLike} \AB{ùì•}, we can define \AF{fresh\textsuperscript{r}} of
type {((\AB{Œì} \AR{‚îÄEnv}) \AB{ùì•} (\AB{Œî} \AF{++} \AB{Œì}))} and \AF{fresh\textsuperscript{l}} of
type {((\AB{Œì} \AR{‚îÄEnv}) \AB{ùì•} (\AB{Œì} \AF{++} \AB{Œî}))} by combining the use
of placeholder values and thinnings. Hence, we can then write a generic \AF{reify}
(\cref{fig:kripkereify}) turning \AF{Kripke} function spaces from \AB{ùì•} to \AB{ùìí}
into \AF{Scope}s of \AB{ùìí} computations.

\begin{figure}[h]
\ExecuteMetaData[shared/Data/Var/Varlike.tex]{reify}
\caption{Generic Reification thanks to \AR{VarLike} Values\label{fig:kripkereify}}
\end{figure}

\section{A Catalogue of Generic Programs for Syntax with Binding}

One of the advantages of having a universe of programming language
descriptions is the ability to concisely define an \emph{extension}
of an existing language by using \AD{Desc}ription transformers
grafting extra constructors √† la Swiestra~(\citeyear{swierstra_2008}).
This is made extremely simple by the
disjoint sum combinator \AF{\_`+\_} we defined in Section~\ref{desccomb}.
An example of such an extension is the addition of let-bindings to
an existing language.

\subsection{Sugar and Desugaring as a Semantics}\label{section:letbinding}

Let bindings allow the user to avoid repeating themselves by naming
sub-expressions and then using these names to refer to the associated
terms. Preprocessors adding these types of mechanisms to existing
languages (from C to CSS) are rather popular. We introduce a
description of \AD{Let}-bindings which can be used to extend any
language description \AB{d} to \AB{d} \AF{`+} \AF{Let} (where \AF{`+}
is the disjoint of sum of two descriptions defined in Figure~\ref{figure:descsum}):

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Examples/ElaborationLet.tex]{letcode}
\caption{Description of a Single Let Binding}
\end{figure}

This description states that a let-binding node stores a pair of types
\AB{$\sigma$} and \AB{$\tau$} and two subterms. First comes the let-bound
expression of type \AB{$\sigma$} and second comes the body of the let which
has type \AB{$\tau$} in a context extended with a fresh variable of type
\AB{$\sigma$}. This defines a term of type \AB{$\tau$}.

In a dependently typed language, a type may depend on a value which
in the presence of let bindings may be a variable standing for an
expression. The user naturally does not want it to make any difference
whether they used a variable referring to a let-bound expression or
the expression itself. Various typechecking strategies can accommodate
this expectation: in Coq~\cite{Coq:manual} let bindings are primitive
constructs of the language and have their own typing and reduction
rules whereas in Agda they are elaborated away to the core language
by inlining.

This latter approach to extending a language \AB{d} with let bindings
by inlining them before typechecking can be implemented generically as
a semantics over (\AB{d} \AF{`+} \AF{Let}). For this semantics values
in the environment and computations are both let-free terms. The algebra
of the semantics can be defined by parts thanks to \AF{case} defined in
\cref{desccomb}: the old constructors are kept the same by interpreting
them using the generic \AF{Substitution} algebra;
whilst the let-binder precisely provides the extra value to be added to the
environment.

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Examples/ElaborationLet.tex]{letelab}
\caption{\AF{Let}-Elaboration as a \AR{Semantics}}
\end{figure}

The process of removing let binders is kickstarted with a placeholder
environment associating each variable to itself.

\begin{figure}[h]
\ExecuteMetaData[generic-syntax.agda/Generic/Examples/ElaborationLet.tex]{unlet}
\caption{Corollary: \AF{Let}-Elaboration via Evaluation with Placeholders}
\end{figure}

In half a dozen lines of code we have defined a generic extension of syntaxes with
binding together with a semantics which corresponds to an elaborator translating
away this new construct. We have seen in \cref{cps-transformation} that it is
similarly possible to implement a Continuation Passing Style transformation as
a semantics for STLC.

We have demonstrated how easily one can define extensions and combine them on top
of a base language without having to reimplement common traversals for each one
of the intermediate representations. Moreover, it is possible to define
\emph{generic} transformations elaborating these added features in terms of
lower-level ones. This suggests that this setup could be a good candidate to
implement generic compilation passes and could deal with a framework using a
wealth of slightly different intermediate languages √† la Nanopass (\cite{Keep:2013:NFC:2544174.2500618}).
